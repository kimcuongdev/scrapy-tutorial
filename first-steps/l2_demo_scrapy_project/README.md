# ğŸš€ Táº¡o Scrapy Project
```bash
scrapy startproject <project_name>
```
# ğŸ“‚ Cáº¥u trÃºc thÆ° má»¥c project cá»§a Scrapy
```
tutorial/
    scrapy.cfg            # file cáº¥u hÃ¬nh cho Scrapy khi cháº¡y project

    tutorial/             # module Python cá»§a project
        __init__.py

        items.py          # mÃ´ táº£ cáº¥u trÃºc dá»¯ liá»‡u trÃ­ch xuáº¥t ra

        middlewares.py    # kiá»ƒm soÃ¡t request/response

        pipelines.py      # xá»­ lÃ½ dá»¯ liá»‡u Ä‘Æ°á»£c yield ra tá»« spiders

        settings.py       # cáº¥u hÃ¬nh project

        spiders/          # chá»©a cÃ¡c spider
            __init__.py
```

# â–¶ï¸ Cháº¡y spider trong Scrapy project
Äá»ƒ cháº¡y spider trong project, Ä‘áº£m báº£o báº¡n Ä‘ang á»Ÿ thÆ° má»¥c project, cháº¡y lá»‡nh:
```bash
scrapy crawl <spider_id>
```

# ğŸ“‘ TrÃ­ch xuáº¥t dá»¯ liá»‡u trong Scrapy

## 1. Sá»­ dá»¥ng CSS Selector
**CÃº phÃ¡p cÆ¡ báº£n:**
```python
response.css("CSS_SELECTOR")
```

- Káº¿t quáº£ tráº£ vá» lÃ  object `SelectorList` (danh sÃ¡ch cÃ¡c node HTML tÃ¬m Ä‘Æ°á»£c).
- Tiáº¿p tá»¥c báº±ng cÃ¡ch láº¥y má»™t káº¿t quáº£ báº±ng `.get()` hoáº·c láº¥y táº¥t cáº£ káº¿t quáº£ báº±ng `.getall()`.

---

### 1.1. VÃ­ dá»¥ minh hoáº¡
Giáº£ sá»­ HTML cÃ³ dáº¡ng:
```html
<div class="quote">
  <span class="text">â€œThe world as we have created it...â€</span>
  <span>by <small class="author">Albert Einstein</small></span>
</div>
```

#### Láº¥y trÃ­ch dáº«n
```python
response.css("div.quote span.text::text").get()
```

#### Láº¥y tÃªn tÃ¡c giáº£
```python
response.css("div.quote small.author::text").get()
```

**Output:**
```python
>>> response.css("div.quote small.author::text").get()
'Albert Einstein'
```

---

### 1.2 CÃ¡c háº­u tá»‘ thÆ°á»ng dÃ¹ng
- **`::text`**: chá»‰ láº¥y pháº§n text trong tag.
```python
>>> response.css("div.quote small.author").get()
'<small class="author" itemprop="author">Albert Einstein</small>'
```

- **`::attr(href)`**: láº¥y giÃ¡ trá»‹ thuá»™c tÃ­nh.

### 1.3. Ngoáº¡i lá»‡
Truy cáº­p vÃ o `SelectorList` rá»—ng sáº½ cho ra ngoáº¡i lá»‡ `IndexError`:
```
>>>response.css("noelement")[0].get()
Traceback (most recent call last):
...
IndexError: list index out of range
```
Thay vÃ o Ä‘Ã³, nÃªn dÃ¹ng `get()` vÃ¬ káº¿t quáº£ tráº£ vá» sáº½ lÃ  `None` náº¿u rá»—ng
```
response.css("noelement").get()
```

## 2. Sá»­ dá»¥ng XPath
### 2.1. CÃº phÃ¡p cÆ¡ báº£n
```python
response.xpath("XPATH_EXPRESSION")
```
* Tráº£ vá» `SelectorList` giá»‘ng `.css()`
* DÃ¹ng `get()` Ä‘á»ƒ láº¥y má»™t káº¿t quáº£ hoáº·c `getall()` Ä‘á»ƒ láº¥y háº¿t

### 2.2 VÃ­ dá»¥ minh hoáº¡
* Giáº£ sá»­ HTML cÃ³ dáº¡ng
```html
<div class="quote">
  <span class="text">â€œThe world as we have created it...â€</span>
  <span>by <small class="author">Albert Einstein</small></span>
</div>
```
* Láº¥y trÃ­ch dáº«n
  * `//div[@class='quote']`: tÃ¬m táº¥t cáº£ tháº» `div` cÃ³ `class` lÃ  `quote` trong HTML
  * `/span[@class='text']`: Ä‘i xuá»‘ng má»©c con, tÃ¬m cÃ¡c tháº» `span` cÃ³ `class` lÃ  `text`
  * `/text()`: láº¥y text bÃªn trong
```python
response.xpath("//div[@class='quote']/span[@class='text']/text()").get()
```
* Láº¥y tÃ¡c giáº£
  * `//small[@class='author']` Ä‘á»ƒ Ä‘i xuá»‘ng báº¥t ká»³ má»©c nÃ o, tÃ¬m tháº» `small`
```python
response.xpath("//div[@class='quote']//small[@class='author']/text()").get()
```

## 3. TrÃ­ch xuáº¥t trong spider
### Tá»« khoÃ¡ `yield`
* `yield` biáº¿n má»™t hÃ m bÃ¬nh thÆ°á»ng thÃ nh *generator function*
* Khi hÃ m cháº¡y Ä‘áº¿n `yield`, nÃ³ tráº£ vá» giÃ¡ trá»‹ Ä‘Ã³ nhÆ°ng *khÃ´ng káº¿t thÃºc hÃ m*
* Láº§n gá»i hÃ m tiáº¿p theo sáº½ tiáº¿p tá»¥c cháº¡y tá»« chá»— `yield` trá»Ÿ Ä‘i
```python
import scrapy

class QuotesSpider(scrapy.Spider):
    name = "quotes"
    start_urls = [
        "https://quotes.toscrape.com/page/1/",
        "https://quotes.toscrape.com/page/2/",
    ]

    def parse(self, response):
        for quote in response.css("div.quote"):
            yield {
                "text": quote.css("span.text::text").get(),
                "author": quote.css("small.author::text").get(),
                "tags": quote.css("div.tags a.tag::text").getall(),
            }
```

# ğŸ’¾ LÆ°u trá»¯ dá»¯ liá»‡u crawl Ä‘Æ°á»£c
## Feed Exports
* Option `-O` Ä‘á»ƒ ghi Ä‘Ã¨ náº¿u file Ä‘Ã£ tá»“n táº¡i
* Option `-o` thay vÃ o Ä‘Ã³ gÃ¡n dá»¯ liá»‡u má»›i vÃ o file Ä‘Ã£ tá»“n táº¡i
```bash
scrapy crawl quotes -O quotes.json
```

# ğŸ”— TÃ¬m Ä‘áº¿n url káº¿ tiáº¿p
* TÃ¬m Ä‘áº¿n má»™t url
```python
next_page = response.css("li.next a::attr(href)").get()
if next_page is not None:
    yield response.follow(next_page, callback=self.parse)
```
* TÃ¬m Ä‘áº¿n táº¥t cáº£ cÃ¡c url
  * `author_page_links = response.css(".author + a")`
    * TÃ¬m Ä‘áº¿n táº¥t cáº£ cÃ¡c link náº±m ngay sau tÃªn cÃ¡c tÃ¡c giáº£, chÃ­nh lÃ  link bio cá»§a tÃ¡c giáº£
      * `response.css(".author + a")`: Tháº» `<a>` Ä‘á»©ng ngay sau pháº§n tá»­ cÃ³ class lÃ  `author`
  * `yield from response.follow_all(author_page_links, self.parse_author)`
    * Vá»›i má»—i link tÃ¬m Ä‘Æ°á»£c, Scrapy sáº½ follow theo Ä‘á»ƒ Ä‘áº¿n bio cá»§a tÃ¡c giáº£ vÃ  gá»i hÃ m `parse_author` Ä‘á»ƒ xá»­ lÃ½.
  * `pagination_links = response.css("li.next a")`
    * Láº¥y link Ä‘áº¿n trang káº¿ tiáº¿p
  * `yield from response.follow_all(pagination_links, self.parse)`
    * Äi Ä‘áº¿n trang káº¿ tiáº¿p vÃ  gá»i hÃ m `parse` Ä‘á»ƒ xá»­ lÃ½
```python
def parse(self, response):
    author_page_links = response.css(".author + a")
    yield from response.follow_all(author_page_links, self.parse_author)

    pagination_links = response.css("li.next a")
    yield from response.follow_all(pagination_links, self.parse)

def parse_author(self, response):
    def extract_with_css(query):
        return response.css(query).get(default="").strip()

    yield {
        "name": extract_with_css("h3.author-title::text"),
        "birthdate": extract_with_css(".author-born-date::text"),
        "bio": extract_with_css(".author-description::text"),
    }
```

# âš™ï¸ Truyá»n tham sá»‘ khi gá»i spider
```bash
scrapy crawl quotes -O quotes-humor.json -a tag=humor
```
* Truyá»n tham sá»‘ sá»­ dá»¥ng option `-a`
```python
import scrapy

class QuotesSpider(scrapy.Spider):
    name = "quotes"

    async def start(self):
        url = "https://quotes.toscrape.com/"
        tag = getattr(self, "tag", None)
        if tag is not None:
            url = url + "tag/" + tag
        yield scrapy.Request(url, self.parse)

    def parse(self, response):
        for quote in response.css("div.quote"):
            yield {
                "text": quote.css("span.text::text").get(),
                "author": quote.css("small.author::text").get(),
            }

        next_page = response.css("li.next a::attr(href)").get()
        if next_page is not None:
            yield response.follow(next_page, self.parse)
```
